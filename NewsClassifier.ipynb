{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cc2027b",
   "metadata": {},
   "source": [
    "# News Headline Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85b0c39",
   "metadata": {},
   "source": [
    "## 1. 准备环境与导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f34791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import re\n",
    "from collections import Counter\n",
    "from typing import List, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 2. 设置随机种子 ———— 42 \n",
    "# 保证可复现性\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    random.seed(seed)                          # Python 内置随机库\n",
    "    torch.manual_seed(seed)                    # PyTorch CPU 随机种子\n",
    "    torch.cuda.manual_seed_all(seed)           # PyTorch GPU (CUDA) 随机种子（如果有）\n",
    "    # 注意：MPS 目前没有完全统一的 manual_seed 接口，但在 CPU/CUDA 上这步是标准的。\n",
    "\n",
    "# 3. 选择计算设备 (Device Selection)\n",
    "force_mps = True\n",
    "if force_mps and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using device: mps (Apple Silicon)\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using device: cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using device: cpu\")\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a68a5ae",
   "metadata": {},
   "source": [
    "## 2. 读取现有文件内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7843fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 读取数据文件\n",
    "data_path = \"DATA/dataset.json\"\n",
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    records = json.load(f)\n",
    "\n",
    "print(f\"样本总数: {len(records)}\")\n",
    "\n",
    "# 2. 统计类别分布\n",
    "import collections\n",
    "labels = [r[\"category\"] for r in records]\n",
    "counter = collections.Counter(labels)\n",
    "print(\"类别分布:\")\n",
    "for k, v in counter.most_common():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9b85bd",
   "metadata": {},
   "source": [
    "## 3. 第一、二个训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55aed02",
   "metadata": {},
   "source": [
    "### 1.数据处理与模型构建\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa669a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 自定义分词器 (Tokenizer) ---\n",
    "# 作用：将文本字符串转换为数字 ID 序列。\n",
    "class WhitespaceTokenizer:\n",
    "    def __init__(self, max_vocab_size: int = 30000, min_freq: int = 2, max_length: int = 64):\n",
    "        self.max_vocab_size = max_vocab_size  # 词表最大容量\n",
    "        self.min_freq = min_freq              # 最小词频，低于此频率的词将被忽略\n",
    "        self.max_length = max_length          # 序列最大长度，超过截断，不足补齐\n",
    "        # 定义特殊 Token\n",
    "        self.pad_token = \"<pad>\"  # 填充符，用于将不同长度的句子补齐到相同长度 (ID=0)\n",
    "        self.unk_token = \"<unk>\"  # 未知词，用于表示词表中不存在的词 (ID=1)\n",
    "        self.cls_token = \"<cls>\"  # 分类符，通常放在句子开头，用于汇聚整个句子的语义 (ID=2)\n",
    "        # 初始化词表映射\n",
    "        self.token_to_id = {self.pad_token: 0, self.unk_token: 1, self.cls_token: 2}\n",
    "        self.id_to_token = {0: self.pad_token, 1: self.unk_token, 2: self.cls_token}\n",
    "\n",
    "    # 简单的分词逻辑：转小写 -> 去首尾空格 -> 按空格切分\n",
    "    # 改进：使用正则切分标点符号，避免 \"apple,\" 和 \"apple\" 被视为不同词\n",
    "    def tokenize(self, text: str) -> List[str]:\n",
    "        text = text.lower().strip()\n",
    "        # \\w+ 匹配单词字符，[^\\w\\s] 匹配标点符号\n",
    "        return re.findall(r\"\\w+|[^\\w\\s]\", text)\n",
    "\n",
    "    # 构建词表：统计所有文本中的词频，选取高频词加入词表\n",
    "    def build_vocab(self, texts: List[str]) -> None:\n",
    "        counter = Counter()\n",
    "        for t in texts:\n",
    "            counter.update(self.tokenize(t))\n",
    "        # 选取最常见的词，过滤掉低频词\n",
    "        most_common = [w for w, c in counter.most_common(self.max_vocab_size) if c >= self.min_freq]\n",
    "        # 将这些词加入映射字典\n",
    "        for idx, token in enumerate(most_common, start=len(self.token_to_id)):\n",
    "            if token not in self.token_to_id:\n",
    "                self.token_to_id[token] = idx\n",
    "                self.id_to_token[idx] = token\n",
    "\n",
    "    # 编码：将文本转换为 ID 序列和 Attention Mask\n",
    "    def encode(self, text: str) -> Tuple[List[int], List[int]]:\n",
    "        # 1. 添加 <cls> 并分词\n",
    "        tokens = [self.cls_token] + self.tokenize(text)\n",
    "        # 2. 截断：如果超过最大长度，切掉后面的\n",
    "        tokens = tokens[: self.max_length]\n",
    "        # 3. 查表转换：将词转为 ID，找不到的转为 <unk>\n",
    "        ids = [self.token_to_id.get(tok, self.token_to_id[self.unk_token]) for tok in tokens]\n",
    "        # 4. 填充：如果长度不足，用 <pad> 补齐\n",
    "        pad_length = self.max_length - len(ids)\n",
    "        if pad_length > 0:\n",
    "            ids += [self.token_to_id[self.pad_token]] * pad_length\n",
    "        # 5. 生成 Mask：1 表示有效内容，0 表示填充内容（模型不应关注填充部分）\n",
    "        # Attention Mask 用于告诉 Self-Attention 机制哪些位置是真实的词，哪些只是填充的占位符\n",
    "        attention_mask = [1 if i != self.token_to_id[self.pad_token] else 0 for i in ids]\n",
    "        return ids, attention_mask\n",
    "\n",
    "\n",
    "# --- 自定义数据集 (Dataset) ---\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, texts: List[str], labels: List[int], tokenizer: WhitespaceTokenizer):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        # 获取第 idx 条数据，并进行编码\n",
    "        ids, mask = self.tokenizer.encode(self.texts[idx])\n",
    "        # 返回 PyTorch 张量 (Tensor)\n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(ids, dtype=torch.long),\n",
    "            \"attention_mask\": torch.tensor(mask, dtype=torch.long),\n",
    "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long),\n",
    "        }\n",
    "\n",
    "\n",
    "# --- 位置编码 (Positional Encoding) ---\n",
    "# 我们需要通过位置编码将“位置信息”注入到输入向量中。\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, max_len: int = 512):\n",
    "        super().__init__()\n",
    "        # 创建一个 max_len x d_model 的矩阵\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        # 使用正弦和余弦函数生成位置信息\n",
    "        # 这种编码方式可以让模型学习到相对位置关系\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        # register_buffer 告诉 PyTorch 这是一个状态，但不是需要更新的参数（梯度为不需要）\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # 将位置编码加到输入的 Embedding 上\n",
    "        # x.size(1) 是当前序列的实际长度\n",
    "        return x + self.pe[:, : x.size(1)]\n",
    "\n",
    "\n",
    "# --- 文本分类模型 (Classifier) ---\n",
    "# 架构：Embedding -> PositionalEncoding -> TransformerEncoder -> Linear Classifier\n",
    "class NewsClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size: int, num_labels: int, d_model: int = 128, num_heads: int = 4, num_layers: int = 2, dim_feedforward: int = 256, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        # 1. 词嵌入层：将整数 ID 映射为 d_model 维的稠密向量\n",
    "        # padding_idx=0 表示 ID 为 0 的词向量始终为 0，不参与更新\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model, padding_idx=0)\n",
    "        \n",
    "        # 2. 位置编码层：给词向量加上位置信息\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "        \n",
    "        # 3. Transformer 编码器层定义\n",
    "        # d_model: 输入向量维度\n",
    "        # nhead: 多头注意力的头数\n",
    "        # dim_feedforward: 前馈神经网络的隐藏层维度\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True, # 输入格式为 (batch, seq, feature)\n",
    "        )\n",
    "        # 4. 堆叠多层 Transformer Encoder\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # 5. 分类头：将 Transformer 的输出映射到类别数量\n",
    "        self.classifier = nn.Linear(d_model, num_labels)\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        # 生成 padding mask \n",
    "        padding_mask = attention_mask == 0\n",
    "        \n",
    "        # 1. 获取词向量并缩放\n",
    "        x = self.embedding(input_ids) * math.sqrt(self.embedding.embedding_dim)\n",
    "        # 2. 加上位置编码\n",
    "        x = self.pos_encoder(x)\n",
    "        # 3. 通过 Transformer 编码器\n",
    "        # src_key_padding_mask 用于屏蔽掉 padding 部分，防止其影响注意力计算\n",
    "        x = self.transformer_encoder(x, src_key_padding_mask=padding_mask)\n",
    "        \n",
    "        # 4. 获取句子表示\n",
    "        # 取第一个 token (<cls>) 的输出作为整个句子的表示\n",
    "        cls_repr = x[:, 0, :]\n",
    "        \n",
    "        # 5. 分类\n",
    "        logits = self.classifier(self.dropout(cls_repr))\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8f422f",
   "metadata": {},
   "source": [
    "### 2. 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dde187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 数据准备函数 ---\n",
    "def prepare_datasets(records, tokenizer: WhitespaceTokenizer, text_key: str = \"headline\", split_ratios: Tuple[float, float, float] = (0.7, 0.15, 0.15)):\n",
    "    \"\"\"\n",
    "    准备数据集\n",
    "    :param records: 原始数据列表\n",
    "    :param tokenizer: 分词器实例\n",
    "    :param text_key: 使用哪个字段作为输入文本 (\"headline\" 或 \"short_description\")\n",
    "    :param split_ratios: (Train, Val, Meta) 的比例\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(records)\n",
    "    \n",
    "    # 确保字段存在，如果不存在则填充空字符串\n",
    "    if text_key not in df.columns:\n",
    "        print(f\"Warning: Key '{text_key}' not found in dataset. Using empty strings.\")\n",
    "        texts = [\"\"] * len(df)\n",
    "    else:\n",
    "        texts = df[text_key].fillna(\"\").tolist()\n",
    "        \n",
    "    labels_raw = df[\"category\"].tolist()\n",
    "\n",
    "    # 1. 构建标签映射 (Label Mapping)\n",
    "    unique_labels = sorted(set(labels_raw))\n",
    "    label2id = {label: i for i, label in enumerate(unique_labels)}\n",
    "    id2label = {i: label for label, i in label2id.items()}\n",
    "    labels = [label2id[l] for l in labels_raw]\n",
    "\n",
    "    # 2. 构建词表 (针对当前指定的文本字段)\n",
    "    tokenizer.build_vocab(texts)\n",
    "\n",
    "    # 3. 创建数据集对象\n",
    "    dataset = NewsDataset(texts, labels, tokenizer)\n",
    "    \n",
    "    # 4. 划分训练集、验证集和 Meta 训练集\n",
    "    total_size = len(dataset)\n",
    "    train_size = int(split_ratios[0] * total_size)\n",
    "    val_size = int(split_ratios[1] * total_size)\n",
    "    meta_size = total_size - train_size - val_size\n",
    "    \n",
    "    # 使用固定种子进行划分，确保不同模型训练时使用的是同一份数据划分\n",
    "    train_ds, val_ds, meta_ds = random_split(\n",
    "        dataset, \n",
    "        [train_size, val_size, meta_size], \n",
    "        generator=torch.Generator().manual_seed(42)\n",
    "    )\n",
    "    \n",
    "    print(f\"Dataset prepared for key='{text_key}': Train={len(train_ds)}, Val={len(val_ds)}, Meta={len(meta_ds)}, Vocab={len(tokenizer.token_to_id)}\")\n",
    "    return train_ds, val_ds, meta_ds, label2id, id2label\n",
    "\n",
    "\n",
    "# --- 数据批处理函数 ---\n",
    "def collate_fn(batch):\n",
    "    input_ids = torch.stack([item[\"input_ids\"] for item in batch])\n",
    "    attention_mask = torch.stack([item[\"attention_mask\"] for item in batch])\n",
    "    labels = torch.stack([item[\"labels\"] for item in batch])\n",
    "    return input_ids, attention_mask, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8609ced",
   "metadata": {},
   "source": [
    "### 3.训练与评估循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858aa1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 核心训练逻辑封装 ---\n",
    "\n",
    "# 训练函数\n",
    "def train_one_epoch(model, dataloader, optimizer, criterion, device, epoch: int, num_epochs: int, prefix: str = \"\", log_every: int = 50):\n",
    "    # 1. 将模型设置为训练模式（启用 Dropout 和 BatchNorm 的更新）\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    # 2. 遍历 DataLoader 中的每一个 Batch\n",
    "    # enumerate(..., start=1) 让 step 从 1 开始计数\n",
    "    for step, (input_ids, attention_mask, labels) in enumerate(dataloader, start=1):\n",
    "        # 3. 将数据移动到计算设备 (MPS)\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # 4. 清空上一步的梯度（PyTorch 默认会累加梯度，所以每次都要清零）\n",
    "        optimizer.zero_grad()\n",
    "        # 5. 前向传播：将数据喂给模型，得到预测结果 (logits)\n",
    "        logits = model(input_ids, attention_mask)\n",
    "        # 6. 计算损失：比较预测结果 logits 和真实标签 labels\n",
    "        loss = criterion(logits, labels)\n",
    "        # 7. 反向传播：计算梯度\n",
    "        loss.backward()\n",
    "        # 8. 参数更新：根据梯度调整模型参数\n",
    "        optimizer.step()\n",
    "\n",
    "        # 累加损失（loss.item() 是平均 loss，乘以 batch_size 得到该 batch 的总 loss）\n",
    "        total_loss += loss.item() * input_ids.size(0)\n",
    "        # 9. 每隔 log_every 步打印一次日志\n",
    "        if step % log_every == 0:\n",
    "            print(f\"[{prefix}] Epoch {epoch}/{num_epochs} | Step {step}/{len(dataloader)} | loss={loss.item():.4f}\")\n",
    "    # 返回整个 Epoch 的平均 Loss\n",
    "    return total_loss / len(dataloader.dataset)\n",
    "\n",
    "# 评估函数\n",
    "def evaluate_detailed(model, dataloader, device, id2label):\n",
    "    # 1. 将模型设置为评估模式（关闭 Dropout，固定 BatchNorm）\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # 2. 禁用梯度计算（节省显存和计算资源，因为评估不需要反向传播）\n",
    "    with torch.no_grad():\n",
    "        for input_ids, attention_mask, labels in dataloader:\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            logits = model(input_ids, attention_mask)\n",
    "            # 3. 获取预测类别：在最后一个维度上取最大值的索引\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "    # 4. 生成详细的分类报告（包含精确率、召回率、F1值）\n",
    "    target_names = [id2label[i] for i in range(len(id2label))]\n",
    "    # zero_division=0 避免某些类别未出现时的警告\n",
    "    report = classification_report(all_labels, all_preds, target_names=target_names, zero_division=0)\n",
    "    print(report)\n",
    "    \n",
    "    # 5. 计算并返回总体准确率 (Accuracy)\n",
    "    correct = sum([1 for p, l in zip(all_preds, all_labels) if p == l])\n",
    "    return correct / len(all_labels)\n",
    "\n",
    "def run_training_pipeline(text_key: str, save_name: str, num_epochs: int = 2):\n",
    "    print(f\"\\n{'='*20} 开始训练模型: {text_key} {'='*20}\")\n",
    "    \n",
    "    # 1. 初始化分词器\n",
    "    tokenizer = WhitespaceTokenizer(max_vocab_size=30000, min_freq=2, max_length=64)\n",
    "    \n",
    "    # 2. 准备数据 (Train / Val / Meta)\n",
    "    train_ds, val_ds, meta_ds, label2id, id2label = prepare_datasets(records, tokenizer, text_key=text_key)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_ds, batch_size=64, shuffle=False, collate_fn=collate_fn)\n",
    "    \n",
    "    # 由于 train_ds 是 Subset，我们需要访问其 underlying dataset\n",
    "    all_labels = [train_ds.dataset.labels[i] for i in train_ds.indices]\n",
    "    label_counts = Counter(all_labels)\n",
    "    # 权重 = 总样本数 / (类别数 * 类别样本数)\n",
    "    total_samples = len(all_labels)\n",
    "    num_classes = len(label2id)\n",
    "    weights = [total_samples / (num_classes * label_counts.get(i, 1)) for i in range(num_classes)]\n",
    "    class_weights = torch.FloatTensor(weights).to(device)\n",
    "    print(f\"Class weights calculated (min={min(weights):.2f}, max={max(weights):.2f})\")\n",
    "\n",
    "    # 3. 初始化模型\n",
    "    model = NewsClassifier(\n",
    "        vocab_size=len(tokenizer.token_to_id),\n",
    "        num_labels=len(label2id),\n",
    "        d_model=128,\n",
    "        num_heads=4,\n",
    "        num_layers=2,\n",
    "        dim_feedforward=256,\n",
    "        dropout=0.1,\n",
    "    ).to(device)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.01)\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=1)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    \n",
    "    # 4. 训练循环\n",
    "    best_val_acc = 0.0\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device, epoch, num_epochs, prefix=text_key)\n",
    "        \n",
    "        print(f\"--- Validation Report Epoch {epoch} ---\")\n",
    "        val_acc = evaluate_detailed(model, val_loader, device, id2label)\n",
    "        print(f\"[{text_key}] Epoch {epoch}/{num_epochs}: train_loss={train_loss:.4f}, val_acc={val_acc:.4f}\")\n",
    "\n",
    "        # 更新学习率\n",
    "        scheduler.step(val_acc)\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save({\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"label2id\": label2id,\n",
    "                \"id2label\": id2label,\n",
    "                \"vocab\": tokenizer.token_to_id,\n",
    "                \"config\": {\n",
    "                    \"d_model\": model.embedding.embedding_dim,\n",
    "                    \"num_heads\": model.transformer_encoder.layers[0].self_attn.num_heads,\n",
    "                    \"num_layers\": len(model.transformer_encoder.layers),\n",
    "                    \"dim_feedforward\": model.transformer_encoder.layers[0].linear1.out_features,\n",
    "                    \"max_length\": tokenizer.max_length,\n",
    "                    \"text_key\": text_key\n",
    "                },\n",
    "            }, save_name)\n",
    "            print(f\"已保存最优模型 ({text_key}): {save_name}\")\n",
    "            \n",
    "    print(f\"[{text_key}] 训练结束，最佳验证准确率: {best_val_acc:.4f}\")\n",
    "    return best_val_acc\n",
    "\n",
    "# --- 并行训练 ---\n",
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "print(f\"\\n{'='*20} 开始并行训练双流模型 {'='*20}\")\n",
    "start_time = time.time()\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    \n",
    "    future_headline = executor.submit(run_training_pipeline, text_key=\"headline\", save_name=\"best_model_headline.pt\", num_epochs=2)\n",
    "    future_desc = executor.submit(run_training_pipeline, text_key=\"short_description\", save_name=\"best_model_description.pt\", num_epochs=2)\n",
    "\n",
    "    acc_headline = future_headline.result()\n",
    "    acc_desc = future_desc.result()\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\n并行训练结束，总耗时: {end_time - start_time:.2f}s\")\n",
    "print(f\"Headline Acc: {acc_headline:.4f}\")\n",
    "print(f\"Description Acc: {acc_desc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b794486b",
   "metadata": {},
   "source": [
    "## 4.第三个模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba303c92",
   "metadata": {},
   "source": [
    "### 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6276af1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 权重模型定义 ---\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 我们使用一个简单的多层感知机 (MLP) 来学习如何组合两个基础模型的输出。\n",
    "# 基础模型 (Base Models): Headline Model, Description Model\n",
    "# 元模型 (Meta Model): 接收基础模型的预测概率，输出最终的预测结果\n",
    "# 输入: [Headline_Probs (N), Description_Probs (N)] -> 维度 2N\n",
    "# 输出: Final_Logits (N)\n",
    "class MetaClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim), # 线性层 1\n",
    "            nn.ReLU(),                        # 激活函数\n",
    "            nn.Dropout(0.2),                  # 防止过拟合\n",
    "            nn.Linear(hidden_dim, output_dim) # 线性层 2 -> 输出最终类别 Logits\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "def load_base_model(path, device):\n",
    "    \"\"\"辅助函数：加载基础模型用于特征提取\"\"\"\n",
    "    # 加载 checkpoint\n",
    "    checkpoint = torch.load(path, map_location=device)\n",
    "    vocab = checkpoint[\"vocab\"]\n",
    "    cfg = checkpoint.get(\"config\", {})\n",
    "    \n",
    "    # 重建分词器\n",
    "    tokenizer = WhitespaceTokenizer(\n",
    "        max_vocab_size=len(vocab),\n",
    "        min_freq=1,\n",
    "        max_length=cfg.get(\"max_length\", 64),\n",
    "    )\n",
    "    tokenizer.token_to_id = vocab\n",
    "    tokenizer.id_to_token = {v: k for k, v in vocab.items()}\n",
    "\n",
    "    # 重建模型结构\n",
    "    model = NewsClassifier(\n",
    "        vocab_size=len(tokenizer.token_to_id),\n",
    "        num_labels=len(checkpoint[\"label2id\"]),\n",
    "        d_model=cfg.get(\"d_model\", 128),\n",
    "        num_heads=cfg.get(\"num_heads\", 4),\n",
    "        num_layers=cfg.get(\"num_layers\", 2),\n",
    "        dim_feedforward=cfg.get(\"dim_feedforward\", 256),\n",
    "        dropout=0.1,\n",
    "    ).to(device)\n",
    "    # 加载模型参数\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    model.eval() # 设置为评估模式\n",
    "    return model, tokenizer, checkpoint[\"label2id\"]\n",
    "\n",
    "def generate_meta_dataset(records, val_indices, model_h, tok_h, model_d, tok_d, label2id, device):\n",
    "    \"\"\"\n",
    "    生成元数据 (Meta-Dataset)\n",
    "    遍历验证集，分别通过两个基础模型，收集它们的预测概率作为 Meta Model 的输入特征。\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    print(f\"Generating meta-features from {len(val_indices)} validation samples...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx in val_indices:\n",
    "            item = records[idx]\n",
    "            label_str = item[\"category\"]\n",
    "            if label_str not in label2id: continue\n",
    "            target = label2id[label_str]\n",
    "            \n",
    "            # 1. Headline Model Prediction (标题模型预测)\n",
    "            h_ids, h_mask = tok_h.encode(item.get(\"headline\", \"\"))\n",
    "            h_in = torch.tensor([h_ids]).to(device)\n",
    "            h_msk = torch.tensor([h_mask]).to(device)\n",
    "            # 获取 Softmax 后的概率分布\n",
    "            probs_h = F.softmax(model_h(h_in, h_msk), dim=1).cpu().tolist()[0]\n",
    "            \n",
    "            # 2. Description Model Prediction (摘要模型预测)\n",
    "            d_ids, d_mask = tok_d.encode(item.get(\"short_description\", \"\"))\n",
    "            d_in = torch.tensor([d_ids]).to(device)\n",
    "            d_msk = torch.tensor([d_mask]).to(device)\n",
    "            # 获取 Softmax 后的概率分布\n",
    "            probs_d = F.softmax(model_d(d_in, d_msk), dim=1).cpu().tolist()[0]\n",
    "            \n",
    "            # 3. Concatenate Features (特征拼接)\n",
    "            # 特征向量 = [标题预测概率分布, 摘要预测概率分布]\n",
    "            # 例如：如果有 5 个类别，probs_h 长度为 5，probs_d 长度为 5，拼接后长度为 10\n",
    "            meta_features = probs_h + probs_d \n",
    "            \n",
    "            X.append(meta_features)\n",
    "            y.append(target)\n",
    "            \n",
    "    return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c218d1",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e8773d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-training set size: 31430\n",
      "Loading base models for meta-training...\n",
      "Generating meta-features from 31430 validation samples...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     27\u001b[39m num_classes = \u001b[38;5;28mlen\u001b[39m(label2id_h)\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# 3. 生成 Meta-Dataset\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# 注意：这里我们使用独立的 Meta 集合，避免数据泄漏\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m X_meta, y_meta = \u001b[43mgenerate_meta_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtok_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtok_d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel2id_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# 4. 划分 Meta-Train / Meta-Val\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# 为了验证 Meta Model 的效果，我们可以再将 Meta 数据集划分为训练和验证\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# 或者简单起见，直接在 Meta 数据集上训练 (因为我们已经有了独立的 Test 集合概念，虽然这里没显式实现)\u001b[39;00m\n\u001b[32m     36\u001b[39m meta_dataset = torch.utils.data.TensorDataset(X_meta, y_meta)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 82\u001b[39m, in \u001b[36mgenerate_meta_dataset\u001b[39m\u001b[34m(records, val_indices, model_h, tok_h, model_d, tok_d, label2id, device)\u001b[39m\n\u001b[32m     80\u001b[39m d_msk = torch.tensor([d_mask]).to(device)\n\u001b[32m     81\u001b[39m \u001b[38;5;66;03m# 获取 Softmax 后的概率分布\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m probs_d = F.softmax(\u001b[43mmodel_d\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_msk\u001b[49m\u001b[43m)\u001b[49m, dim=\u001b[32m1\u001b[39m).cpu().tolist()[\u001b[32m0\u001b[39m]\n\u001b[32m     84\u001b[39m \u001b[38;5;66;03m# 3. Concatenate Features (特征拼接)\u001b[39;00m\n\u001b[32m     85\u001b[39m \u001b[38;5;66;03m# 特征向量 = [标题预测概率分布, 摘要预测概率分布]\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[38;5;66;03m# 例如：如果有 5 个类别，probs_h 长度为 5，probs_d 长度为 5，拼接后长度为 10\u001b[39;00m\n\u001b[32m     87\u001b[39m meta_features = probs_h + probs_d \n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 132\u001b[39m, in \u001b[36mNewsClassifier.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask)\u001b[39m\n\u001b[32m    130\u001b[39m x = \u001b[38;5;28mself\u001b[39m.pos_encoder(x)\n\u001b[32m    131\u001b[39m \u001b[38;5;66;03m# 3. 通过 Transformer 编码器\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransformer_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[38;5;66;03m# 4. 获取句子表示\u001b[39;00m\n\u001b[32m    135\u001b[39m \u001b[38;5;66;03m# 这里我们简单地取第一个 token (<cls>) 的输出作为整个句子的表示\u001b[39;00m\n\u001b[32m    136\u001b[39m cls_repr = x[:, \u001b[32m0\u001b[39m, :]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/transformer.py:524\u001b[39m, in \u001b[36mTransformerEncoder.forward\u001b[39m\u001b[34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[39m\n\u001b[32m    521\u001b[39m is_causal = _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m--> \u001b[39m\u001b[32m524\u001b[39m     output = \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[43m        \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m        \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[32m    532\u001b[39m     output = output.to_padded_tensor(\u001b[32m0.0\u001b[39m, src.size())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/transformer.py:935\u001b[39m, in \u001b[36mTransformerEncoderLayer.forward\u001b[39m\u001b[34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[39m\n\u001b[32m    931\u001b[39m     x = x + \u001b[38;5;28mself\u001b[39m._ff_block(\u001b[38;5;28mself\u001b[39m.norm2(x))\n\u001b[32m    932\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    933\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.norm1(\n\u001b[32m    934\u001b[39m         x\n\u001b[32m--> \u001b[39m\u001b[32m935\u001b[39m         + \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    936\u001b[39m     )\n\u001b[32m    937\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.norm2(x + \u001b[38;5;28mself\u001b[39m._ff_block(x))\n\u001b[32m    939\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/transformer.py:949\u001b[39m, in \u001b[36mTransformerEncoderLayer._sa_block\u001b[39m\u001b[34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[39m\n\u001b[32m    942\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_sa_block\u001b[39m(\n\u001b[32m    943\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    944\u001b[39m     x: Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    947\u001b[39m     is_causal: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    948\u001b[39m ) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m949\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m    958\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dropout1(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/activation.py:1380\u001b[39m, in \u001b[36mMultiheadAttention.forward\u001b[39m\u001b[34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[39m\n\u001b[32m   1354\u001b[39m     attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[32m   1355\u001b[39m         query,\n\u001b[32m   1356\u001b[39m         key,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1377\u001b[39m         is_causal=is_causal,\n\u001b[32m   1378\u001b[39m     )\n\u001b[32m   1379\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1380\u001b[39m     attn_output, attn_output_weights = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1381\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1382\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1383\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1384\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1385\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1386\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1387\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1388\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1389\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1390\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1391\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1392\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mout_proj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1393\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mout_proj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1394\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1395\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1396\u001b[39m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1397\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1398\u001b[39m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1399\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1400\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.batch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[32m   1402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output.transpose(\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m), attn_output_weights\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/functional.py:6304\u001b[39m, in \u001b[36mmulti_head_attention_forward\u001b[39m\u001b[34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[39m\n\u001b[32m   6300\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_separate_proj_weight:\n\u001b[32m   6301\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m in_proj_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, (\n\u001b[32m   6302\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33muse_separate_proj_weight is False but in_proj_weight is None\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   6303\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m6304\u001b[39m     q, k, v = \u001b[43m_in_projection_packed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_proj_bias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6306\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m q_proj_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, (\n\u001b[32m   6307\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33muse_separate_proj_weight is True but q_proj_weight is None\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   6308\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/functional.py:5695\u001b[39m, in \u001b[36m_in_projection_packed\u001b[39m\u001b[34m(q, k, v, w, b)\u001b[39m\n\u001b[32m   5692\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mis\u001b[39;00m v:\n\u001b[32m   5693\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m q \u001b[38;5;129;01mis\u001b[39;00m k:\n\u001b[32m   5694\u001b[39m         \u001b[38;5;66;03m# self-attention\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5695\u001b[39m         proj = \u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5696\u001b[39m         \u001b[38;5;66;03m# reshape to 3, E and not E, 3 is deliberate for better memory coalescing and keeping same order as chunk()\u001b[39;00m\n\u001b[32m   5697\u001b[39m         proj = (\n\u001b[32m   5698\u001b[39m             proj.unflatten(-\u001b[32m1\u001b[39m, (\u001b[32m3\u001b[39m, E))\n\u001b[32m   5699\u001b[39m             .unsqueeze(\u001b[32m0\u001b[39m)\n\u001b[32m   (...)\u001b[39m\u001b[32m   5702\u001b[39m             .contiguous()\n\u001b[32m   5703\u001b[39m         )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# --- 训练 Meta Model ---\n",
    "\n",
    "# 1. 重新获取数据集划分 (获取 Meta 训练集)\n",
    "# 必须与 prepare_datasets 中的划分逻辑完全一致\n",
    "full_ds_size = len(records)\n",
    "train_size = int(0.7 * full_ds_size)\n",
    "val_size = int(0.15 * full_ds_size)\n",
    "meta_size = full_ds_size - train_size - val_size\n",
    "\n",
    "# 使用相同的 seed=42 复现划分\n",
    "_, _, meta_subset = random_split(\n",
    "    range(full_ds_size), \n",
    "    [train_size, val_size, meta_size], \n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "meta_indices = meta_subset.indices\n",
    "\n",
    "print(f\"Meta-training set size: {len(meta_indices)}\")\n",
    "\n",
    "# 2. 加载已训练的基础模型\n",
    "print(\"Loading base models for meta-training...\")\n",
    "model_h, tok_h, label2id_h = load_base_model(\"best_model_headline.pt\", device)\n",
    "model_d, tok_d, label2id_d = load_base_model(\"best_model_description.pt\", device)\n",
    "\n",
    "# 确保标签映射一致\n",
    "assert label2id_h == label2id_d, \"Label mappings do not match!\"\n",
    "num_classes = len(label2id_h)\n",
    "\n",
    "# 3. 生成 Meta-Dataset\n",
    "# 注意：这里我们使用独立的 Meta 集合，避免数据泄漏\n",
    "X_meta, y_meta = generate_meta_dataset(records, meta_indices, model_h, tok_h, model_d, tok_d, label2id_h, device)\n",
    "\n",
    "# 4. 划分 Meta-Train / Meta-Val\n",
    "# 为了验证 Meta Model 的效果，我们可以再将 Meta 数据集划分为训练和验证\n",
    "# 或者简单起见，直接在 Meta 数据集上训练 (因为我们已经有了独立的 Test 集合概念，虽然这里没显式实现)\n",
    "meta_dataset = torch.utils.data.TensorDataset(X_meta, y_meta)\n",
    "meta_loader = DataLoader(meta_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# 5. 初始化 Meta Model\n",
    "# 输入维度 = 类别数 * 2 (两个模型的概率分布拼接)\n",
    "meta_model = MetaClassifier(input_dim=num_classes * 2, hidden_dim=64, output_dim=num_classes).to(device)\n",
    "meta_optimizer = torch.optim.Adam(meta_model.parameters(), lr=0.001)\n",
    "meta_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 6. 训练循环\n",
    "print(f\"\\n{'='*20} 开始训练 Meta Model (权重融合) {'='*20}\")\n",
    "num_meta_epochs = 10 # Meta Model 很小，收敛快\n",
    "for epoch in range(1, num_meta_epochs + 1):\n",
    "    meta_model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for features, labels in meta_loader:\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        meta_optimizer.zero_grad()\n",
    "        logits = meta_model(features)\n",
    "        loss = meta_criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        meta_optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * features.size(0)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        \n",
    "    avg_loss = total_loss / total\n",
    "    acc = correct / total\n",
    "    if epoch % 2 == 0:\n",
    "        print(f\"Meta Epoch {epoch}/{num_meta_epochs}: loss={avg_loss:.4f}, acc={acc:.4f}\")\n",
    "\n",
    "# 7. 保存 Meta Model\n",
    "torch.save(meta_model.state_dict(), \"best_meta_model.pt\")\n",
    "print(\"已保存 Meta Model: best_meta_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d22ccd",
   "metadata": {},
   "source": [
    "## 5.模型使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe41bc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class SingleModelPredictor:\n",
    "    \"\"\"单个模型的预测器封装\"\"\"\n",
    "    def __init__(self, checkpoint_path, device):\n",
    "        self.device = device\n",
    "        self.model, self.tokenizer, self.id2label, self.config = self._load_model(checkpoint_path)\n",
    "        \n",
    "    def _load_model(self, checkpoint_path):\n",
    "        if not os.path.exists(checkpoint_path):\n",
    "            raise FileNotFoundError(f\"Model file not found: {checkpoint_path}\")\n",
    "            \n",
    "        checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "        vocab = checkpoint[\"vocab\"]\n",
    "        label2id = checkpoint[\"label2id\"]\n",
    "        id2label = checkpoint[\"id2label\"]\n",
    "        cfg = checkpoint.get(\"config\", {})\n",
    "\n",
    "        tokenizer = WhitespaceTokenizer(\n",
    "            max_vocab_size=len(vocab),\n",
    "            min_freq=1,\n",
    "            max_length=cfg.get(\"max_length\", 64),\n",
    "        )\n",
    "        tokenizer.token_to_id = vocab\n",
    "        tokenizer.id_to_token = {v: k for k, v in vocab.items()}\n",
    "\n",
    "        model = NewsClassifier(\n",
    "            vocab_size=len(tokenizer.token_to_id),\n",
    "            num_labels=len(label2id),\n",
    "            d_model=cfg.get(\"d_model\", 128),\n",
    "            num_heads=cfg.get(\"num_heads\", 4),\n",
    "            num_layers=cfg.get(\"num_layers\", 2),\n",
    "            dim_feedforward=cfg.get(\"dim_feedforward\", 256),\n",
    "            dropout=0.1,\n",
    "        ).to(self.device)\n",
    "        \n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        model.eval()\n",
    "        return model, tokenizer, id2label, cfg\n",
    "\n",
    "    def get_probs(self, text: str):\n",
    "        \"\"\"返回预测概率分布 (Softmax output)\"\"\"\n",
    "        ids, attn = self.tokenizer.encode(text)\n",
    "        input_ids = torch.tensor([ids], dtype=torch.long).to(self.device)\n",
    "        attention_mask = torch.tensor([attn], dtype=torch.long).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = self.model(input_ids, attention_mask)\n",
    "            probs = F.softmax(logits, dim=1) # 转换为概率\n",
    "        return probs\n",
    "\n",
    "\n",
    "class EnsemblePredictor:\n",
    "    \"\"\"集成预测器：结合标题模型和摘要模型的结果\"\"\"\n",
    "    def __init__(self, headline_model_path=\"best_model_headline.pt\", desc_model_path=\"best_model_description.pt\", meta_model_path=\"best_meta_model.pt\", device=device):\n",
    "        self.device = device\n",
    "        self.headline_predictor = None\n",
    "        self.desc_predictor = None\n",
    "        self.meta_model = None\n",
    "        \n",
    "        # 1. 加载基础模型\n",
    "        if os.path.exists(headline_model_path):\n",
    "            print(f\"Loading Headline Model from {headline_model_path}...\")\n",
    "            self.headline_predictor = SingleModelPredictor(headline_model_path, device)\n",
    "        \n",
    "        if os.path.exists(desc_model_path):\n",
    "            print(f\"Loading Description Model from {desc_model_path}...\")\n",
    "            self.desc_predictor = SingleModelPredictor(desc_model_path, device)\n",
    "            \n",
    "        # 2. 加载 Meta Model (权重模型)\n",
    "        if os.path.exists(meta_model_path) and self.headline_predictor and self.desc_predictor:\n",
    "            print(f\"Loading Meta Model from {meta_model_path}...\")\n",
    "            num_classes = len(self.headline_predictor.id2label)\n",
    "            # Meta Model 输入维度是两个基础模型类别数之和\n",
    "            self.meta_model = MetaClassifier(input_dim=num_classes * 2, hidden_dim=64, output_dim=num_classes).to(device)\n",
    "            self.meta_model.load_state_dict(torch.load(meta_model_path, map_location=device))\n",
    "            self.meta_model.eval()\n",
    "        else:\n",
    "            print(\"Warning: Meta Model not loaded (or base models missing). Will use simple averaging if needed.\")\n",
    "\n",
    "        # 设置 id2label (假设两个模型标签一致)\n",
    "        if self.headline_predictor:\n",
    "            self.id2label = self.headline_predictor.id2label\n",
    "        elif self.desc_predictor:\n",
    "            self.id2label = self.desc_predictor.id2label\n",
    "        else:\n",
    "            raise RuntimeError(\"No models loaded! Please train models first.\")\n",
    "\n",
    "    def predict(self, headline: str = \"\", description: str = \"\"):\n",
    "        \"\"\"\n",
    "        综合预测函数 (使用 Meta Model 进行融合)\n",
    "        \"\"\"\n",
    "        probs_h = None\n",
    "        probs_d = None\n",
    "        \n",
    "        # 1. 获取基础模型预测\n",
    "        if headline and self.headline_predictor:\n",
    "            probs_h = self.headline_predictor.get_probs(headline)\n",
    "            \n",
    "        if description and self.desc_predictor:\n",
    "            probs_d = self.desc_predictor.get_probs(description)\n",
    "            \n",
    "        # 2. 综合决策逻辑\n",
    "        if probs_h is not None and probs_d is not None:\n",
    "            # Case 3: 两者都有 -> 使用 Meta Model 融合\n",
    "            if self.meta_model:\n",
    "                # 拼接特征: [probs_h, probs_d]\n",
    "                meta_input = torch.cat([probs_h, probs_d], dim=1)\n",
    "                with torch.no_grad():\n",
    "                    final_logits = self.meta_model(meta_input)\n",
    "                    final_probs = F.softmax(final_logits, dim=1)\n",
    "                # print(\"Mode: Ensemble (Meta Model)\")\n",
    "            else:\n",
    "                # Fallback: 简单平均 (如果没有训练 Meta Model)\n",
    "                final_probs = 0.6 * probs_h + 0.4 * probs_d\n",
    "                # print(\"Mode: Ensemble (Simple Average)\")\n",
    "                \n",
    "        elif probs_h is not None:\n",
    "            # Case 1: 只有标题 (例如摘要缺失)\n",
    "            final_probs = probs_h\n",
    "            # print(\"Mode: Headline Only\")\n",
    "        elif probs_d is not None:\n",
    "            # Case 2: 只有摘要 (例如标题缺失)\n",
    "            final_probs = probs_d\n",
    "            # print(\"Mode: Description Only\")\n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "            \n",
    "        # 获取最大概率对应的类别\n",
    "        pred_idx = torch.argmax(final_probs, dim=1).item()\n",
    "        return self.id2label[pred_idx]\n",
    "\n",
    "# --- 示例运行 ---\n",
    "try:\n",
    "    ensemble = EnsemblePredictor()\n",
    "    \n",
    "    test_cases = [\n",
    "        {\n",
    "            \"headline\": \"NASA announces new moon mission\", \n",
    "            \"desc\": \"The space agency revealed plans for the Artemis program to return humans to the lunar surface.\"\n",
    "        },\n",
    "        {\n",
    "            \"headline\": \"Stocks surge as tech leads the rally\", \n",
    "            \"desc\": \"\" # 缺失摘要\n",
    "        },\n",
    "        {\n",
    "            \"headline\": \"\", # 缺失标题\n",
    "            \"desc\": \"A new study published in Nature shows that daily meditation can reduce stress levels significantly.\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n--- Inference Results ---\")\n",
    "    for case in test_cases:\n",
    "        h = case[\"headline\"]\n",
    "        d = case[\"desc\"]\n",
    "        pred = ensemble.predict(headline=h, description=d)\n",
    "        print(f\"Headline: {h[:30]}... | Desc: {d[:30]}... -> Prediction: {pred}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error during inference: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    print(\"请确保已运行上方的训练单元并生成了 .pt 模型文件。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
